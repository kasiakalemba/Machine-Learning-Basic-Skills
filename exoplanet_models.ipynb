{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Machine Learning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "#!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the provided dataset\n",
    "df = pd.read_csv(\"data/exoplanet_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition       object\n",
       "koi_fpflag_nt          int64\n",
       "koi_fpflag_ss          int64\n",
       "koi_fpflag_co          int64\n",
       "koi_fpflag_ec          int64\n",
       "koi_period           float64\n",
       "koi_period_err1      float64\n",
       "koi_period_err2      float64\n",
       "koi_time0bk          float64\n",
       "koi_time0bk_err1     float64\n",
       "koi_time0bk_err2     float64\n",
       "koi_impact           float64\n",
       "koi_impact_err1      float64\n",
       "koi_impact_err2      float64\n",
       "koi_duration         float64\n",
       "koi_duration_err1    float64\n",
       "koi_duration_err2    float64\n",
       "koi_depth            float64\n",
       "koi_depth_err1       float64\n",
       "koi_depth_err2       float64\n",
       "koi_prad             float64\n",
       "koi_prad_err1        float64\n",
       "koi_prad_err2        float64\n",
       "koi_teq                int64\n",
       "koi_insol            float64\n",
       "koi_insol_err1       float64\n",
       "koi_insol_err2       float64\n",
       "koi_model_snr        float64\n",
       "koi_tce_plnt_num       int64\n",
       "koi_steff              int64\n",
       "koi_steff_err1         int64\n",
       "koi_steff_err2         int64\n",
       "koi_slogg            float64\n",
       "koi_slogg_err1       float64\n",
       "koi_slogg_err2       float64\n",
       "koi_srad             float64\n",
       "koi_srad_err1        float64\n",
       "koi_srad_err2        float64\n",
       "ra                   float64\n",
       "dec                  float64\n",
       "koi_kepmag           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "# all are numbers expect koi_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking unique values \n",
    "types = df[\"koi_disposition\"].unique()\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition      0\n",
       "koi_fpflag_nt        0\n",
       "koi_fpflag_ss        0\n",
       "koi_fpflag_co        0\n",
       "koi_fpflag_ec        0\n",
       "koi_period           0\n",
       "koi_period_err1      0\n",
       "koi_period_err2      0\n",
       "koi_time0bk          0\n",
       "koi_time0bk_err1     0\n",
       "koi_time0bk_err2     0\n",
       "koi_impact           0\n",
       "koi_impact_err1      0\n",
       "koi_impact_err2      0\n",
       "koi_duration         0\n",
       "koi_duration_err1    0\n",
       "koi_duration_err2    0\n",
       "koi_depth            0\n",
       "koi_depth_err1       0\n",
       "koi_depth_err2       0\n",
       "koi_prad             0\n",
       "koi_prad_err1        0\n",
       "koi_prad_err2        0\n",
       "koi_teq              0\n",
       "koi_insol            0\n",
       "koi_insol_err1       0\n",
       "koi_insol_err2       0\n",
       "koi_model_snr        0\n",
       "koi_tce_plnt_num     0\n",
       "koi_steff            0\n",
       "koi_steff_err1       0\n",
       "koi_steff_err2       0\n",
       "koi_slogg            0\n",
       "koi_slogg_err1       0\n",
       "koi_slogg_err2       0\n",
       "koi_srad             0\n",
       "koi_srad_err1        0\n",
       "koi_srad_err2        0\n",
       "ra                   0\n",
       "dec                  0\n",
       "koi_kepmag           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nans\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x as every column except koi_dis\n",
    "X = df.drop(\"koi_disposition\", axis=1)\n",
    "# Set y to koi_dis\n",
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10939353197544172, 'koi_fpflag_co'),\n",
       " (0.10008082512238897, 'koi_fpflag_nt'),\n",
       " (0.06419056023606082, 'koi_fpflag_ss'),\n",
       " (0.052684753334835854, 'koi_model_snr'),\n",
       " (0.04575429574223963, 'koi_prad'),\n",
       " (0.038166699138336466, 'koi_prad_err1'),\n",
       " (0.0380261966149015, 'koi_prad_err2'),\n",
       " (0.03743492217871771, 'koi_fpflag_ec'),\n",
       " (0.03712087881874025, 'koi_duration_err2'),\n",
       " (0.03462981362060653, 'koi_duration_err1'),\n",
       " (0.02764542599573727, 'koi_steff_err1'),\n",
       " (0.02636664854004471, 'koi_steff_err2'),\n",
       " (0.023584268300264853, 'koi_duration'),\n",
       " (0.02330919808713343, 'koi_time0bk_err2'),\n",
       " (0.021677139088098783, 'koi_time0bk_err1'),\n",
       " (0.021608510484762068, 'koi_period'),\n",
       " (0.01918744440959643, 'koi_depth'),\n",
       " (0.018344683313247706, 'koi_impact'),\n",
       " (0.018337828336907405, 'koi_insol_err1'),\n",
       " (0.01676233101128894, 'koi_period_err1'),\n",
       " (0.016102567392253152, 'koi_period_err2'),\n",
       " (0.015387993859888562, 'koi_teq'),\n",
       " (0.015372740804538144, 'koi_insol_err2'),\n",
       " (0.014876972597654374, 'koi_insol'),\n",
       " (0.014006067480904247, 'koi_depth_err1'),\n",
       " (0.013591491826005725, 'koi_depth_err2'),\n",
       " (0.013503053433610922, 'koi_time0bk'),\n",
       " (0.011950964836934252, 'koi_srad_err1'),\n",
       " (0.011922028326274332, 'ra'),\n",
       " (0.010827453820162697, 'dec'),\n",
       " (0.010776352925879472, 'koi_kepmag'),\n",
       " (0.010631406912149099, 'koi_impact_err2'),\n",
       " (0.010513959023821325, 'koi_impact_err1'),\n",
       " (0.009580167430204602, 'koi_slogg_err2'),\n",
       " (0.009273776368315601, 'koi_srad'),\n",
       " (0.009023736098730976, 'koi_steff'),\n",
       " (0.00860299456453134, 'koi_slogg'),\n",
       " (0.008502299230604742, 'koi_srad_err2'),\n",
       " (0.008121500809274446, 'koi_slogg_err1'),\n",
       " (0.0031265179089109457, 'koi_tce_plnt_num')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X,y)\n",
    "\n",
    "# Get the most important features\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing the top important features\n",
    "X = df[['koi_fpflag_co', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_model_snr', 'koi_prad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data up between training and testing data (3/4:1/4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "# do not scale Y because it is categorical \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model & Tune Hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is used when the dependent variable(target) is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
    "logistic_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameter grid \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'penalty': ('l2', 'none')}\n",
    "\n",
    "# Set up the grid search\n",
    "logistic = GridSearchCV(logistic_classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(logistic.best_params_)\n",
    "\n",
    "# List the best score\n",
    "print(logistic.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "logistic_model = logistic.best_estimator_\n",
    "print(f\"Logistic Model Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logistic Model Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'models/logistic_model.sav'\n",
    "joblib.dump(logistic_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In the SVM algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates the two classes very well.\" - www.analyticsvidhya.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# creates SVC model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {'C': [1, 5, 10, 50], \n",
    "             'gamma': [1,5,10,50,100]}\n",
    "\n",
    "# grid search\n",
    "svm_grid = GridSearchCV(svm_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the model\n",
    "svm_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for the grid search\n",
    "print(svm_grid.best_params_)\n",
    "print(svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Score\n",
    "svm_model = svm_grid.best_estimator_\n",
    "print(f\"SVM Training Data Score: {svm_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVM Testing Data Score: {svm_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'models/svm.sav'\n",
    "joblib.dump(logistic_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our modelâ€™s prediction.\" - TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up random forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {'max_depth': [1, 5, 50], \n",
    "             \"n_estimators\": [250, 500, 1000, 1500],\n",
    "             \"min_samples_leaf\": [1, 2, 5, 10]}\n",
    "\n",
    "# sets up the random forest grid search\n",
    "rf_grid = GridSearchCV(rf_model, param_grid, verbose=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the random forest\n",
    "rf_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out the best parameters \n",
    "print(rf_grid.best_params_)\n",
    "print(rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Scoring\n",
    "rf_model = rf_grid.best_estimator_\n",
    "print(f\"RF Training Data Score: {rf_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RF Testing Data Score: {rf_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'models/logistic_model.sav'\n",
    "joblib.dump(logistic_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\" - TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates k nearest neighbor model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {\"leaf_size\": [1, 10, 100, 200],\n",
    "                \"n_neighbors\": list(range(1, 20, 2))}\n",
    "\n",
    "# sets up the grid search\n",
    "knn_grid = GridSearchCV(knn_model, param_grid, verbose=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the k nearest neighbor/grid search model to X and y\n",
    "knn_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out the best parameters \n",
    "print(knn_grid.best_params_)\n",
    "print(knn_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbor Model Scoring\n",
    "knn_model = knn_grid.best_estimator_\n",
    "print(f\"KNN Training Data Score: {knn_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"KNN Testing Data Score: {knn_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic Model Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logistic Model Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "print(f\"SVM Training Data Score: {svm_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVM Testing Data Score: {svm_model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"RF Training Data Score: {rf_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RF Testing Data Score: {rf_model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"KNN Training Data Score: {knn_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"KNN Testing Data Score: {knn_model.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
