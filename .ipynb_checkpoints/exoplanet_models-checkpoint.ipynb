{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Machine Learning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "#!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the provided dataset\n",
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# all are numbers expect koi_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique values \n",
    "types = df[\"koi_disposition\"].unique()\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for nans\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x as every column except koi_dis\n",
    "X = df.drop(\"koi_disposition\", axis=1)\n",
    "# Set y to koi_dis\n",
    "y = df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X,y)\n",
    "\n",
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "# in this case it would be the petal \n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing the top important features\n",
    "X = df[['koi_fpflag_co', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_model_snr', 'koi_prad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data up between training and testing data (3/4:1/4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "# do not scale Y because it is categorical \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model & Tune Hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is used when the dependent variable(target) is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
    "logistic_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameter grid \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'penalty': ('l2', 'none')}\n",
    "\n",
    "# Set up the grid search\n",
    "logistic = GridSearchCV(logistic_classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(logistic.best_params_)\n",
    "\n",
    "# List the best score\n",
    "print(logistic.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "logistic_model = logistic.best_estimator_\n",
    "print(f\"Logistic Model Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logistic Model Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'logistic_model.sav'\n",
    "joblib.dump(logistic_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In the SVM algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates the two classes very well.\" - www.analyticsvidhya.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# creates SVC model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {'C': [1, 5, 10, 50], \n",
    "             'gamma': [1,5,10,50,100]}\n",
    "\n",
    "# grid search\n",
    "svm_grid = GridSearchCV(svm_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the model\n",
    "svm_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for the grid search\n",
    "print(svm_grid.best_params_)\n",
    "print(svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Score\n",
    "svm_model = svm_grid.best_estimator_\n",
    "print(f\"SVM Training Data Score: {svm_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVM Testing Data Score: {svm_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our modelâ€™s prediction.\" - TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up random forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {'max_depth': [1, 5, 50], \n",
    "             \"n_estimators\": [250, 500, 1000, 1500],\n",
    "             \"min_samples_leaf\": [1, 2, 5, 10]}\n",
    "\n",
    "# sets up the random forest grid search\n",
    "rf_grid = GridSearchCV(rf_model, param_grid, verbose=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the random forest\n",
    "rf_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out the best parameters \n",
    "print(rf_grid.best_params_)\n",
    "print(rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Scoring\n",
    "rf_model = rf_grid.best_estimator_\n",
    "print(f\"RF Training Data Score: {rf_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RF Testing Data Score: {rf_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\" - TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates k nearest neighbor model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up hyperparameter grid\n",
    "param_grid = {\"leaf_size\": [1, 10, 100, 200],\n",
    "                \"n_neighbors\": list(range(1, 20, 2))}\n",
    "\n",
    "# sets up the grid search\n",
    "knn_grid = GridSearchCV(knn_model, param_grid, verbose=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits the k nearest neighbor/grid search model to X and y\n",
    "knn_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out the best parameters \n",
    "print(knn_grid.best_params_)\n",
    "print(knn_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbor Model Scoring\n",
    "knn_model = knn_grid.best_estimator_\n",
    "print(f\"KNN Training Data Score: {knn_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"KNN Testing Data Score: {knn_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic Model Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logistic Model Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "print(f\"SVM Training Data Score: {svm_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVM Testing Data Score: {svm_model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"RF Training Data Score: {rf_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RF Testing Data Score: {rf_model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"KNN Training Data Score: {knn_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"KNN Testing Data Score: {knn_model.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
